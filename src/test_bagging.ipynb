{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raw_python.Bagging import create_models, create_bags, evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from raw_python.BaggingSA import BaggingSA\n",
    "from raw_python.DatasetsHandle import get_dataset\n",
    "from tabulate import tabulate\n",
    "\n",
    "seed = 41\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_name = 'students_dropout'\n",
    "k_cross = 5\n",
    "reps = 5\n",
    "params = {\n",
    "    'T0': 2,\n",
    "    'cooling_method': 'geometric',\n",
    "    'alpha': 0.995,\n",
    "    'max_iterations': 2000,\n",
    "    'feature_mutation_chance': 0.25,\n",
    "    'test_split_amount': 5,\n",
    "    'theta': 0.85,\n",
    "    'beta': 0.1,\n",
    "    'gamma': 0.05,\n",
    "    'n_trees': 10,\n",
    "    'pop_size':1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "def evaluate_bagging(X_train, y_train, X_test, y_test):\n",
    "    n_trees = params['n_trees']\n",
    "    bags = create_bags(X_train, y_train, bags_amount=n_trees)\n",
    "    models = create_models(bags=bags)\n",
    "    accuracy = evaluate(X=X_test, y=y_test, models=models)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def evaluate_bagging_sa(X_train, y_train, X_test, y_test):\n",
    "    T0 = params['T0']\n",
    "    cooling_method = params['cooling_method']\n",
    "    alpha = params['alpha']\n",
    "    max_iterations = params['max_iterations']\n",
    "    feature_mutation_chance = params['feature_mutation_chance']\n",
    "    test_split_amount = params['test_split_amount']\n",
    "    n_trees = params['n_trees']\n",
    "    theta = params['theta']\n",
    "    beta = params['beta']\n",
    "    gamma = params['gamma']\n",
    "    bagging_sa = BaggingSA(X=X_train, y=y_train,\n",
    "                            T0=T0, cooling_method=cooling_method, alpha=alpha, max_iterations=max_iterations, n_trees=n_trees,\n",
    "                            feature_mutation_chance=feature_mutation_chance, test_split_amount=test_split_amount, theta=theta, beta=beta, gamma=gamma)\n",
    "    models, fitness = bagging_sa.run(X_for_test=X_test, y_for_test=y_test, monitor_fun=fun_monitor, get_fitness=True)\n",
    "    accuracy = evaluate(X_test, y_test, models=models)\n",
    "    return accuracy, models, fitness\n",
    "\n",
    "def fun_monitor(iteration, T, best_fitness, fitness, new_fitness, accuracy):\n",
    "    if accuracy is None:\n",
    "        accuracy = 0.0\n",
    "    # print(f\"    I: {iteration}, T: {T:.3f}, Best fitness: {best_fitness:.3f}, Fitness: {fitness:.3f}, New fitness: {new_fitness:.3f}, Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaggingSA.__init__() got an unexpected keyword argument 'theta'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(reps):\n\u001b[32m     17\u001b[39m     acc_bagging = evaluate_bagging(X_train, y_train, X_test, y_test)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     accuracy, models, fitness = \u001b[43mevaluate_bagging_sa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     result.append([k+\u001b[32m1\u001b[39m, r+\u001b[32m1\u001b[39m, fitness, accuracy, acc_bagging, acc_bagging_random])\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk+\u001b[32m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_cross\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Rep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr+\u001b[32m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreps\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Fitness: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfitness\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Bagging: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_bagging\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, BaggingRandom: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_bagging_random\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mevaluate_bagging_sa\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test)\u001b[39m\n\u001b[32m     23\u001b[39m beta = params[\u001b[33m'\u001b[39m\u001b[33mbeta\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     24\u001b[39m gamma = params[\u001b[33m'\u001b[39m\u001b[33mgamma\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m bagging_sa = \u001b[43mBaggingSA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mT0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mT0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcooling_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcooling_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trees\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trees\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mfeature_mutation_chance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_mutation_chance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_split_amount\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_split_amount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m models, fitness = bagging_sa.run(X_for_test=X_test, y_for_test=y_test, monitor_fun=fun_monitor, get_fitness=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     29\u001b[39m accuracy = evaluate(X_test, y_test, models=models)\n",
      "\u001b[31mTypeError\u001b[39m: BaggingSA.__init__() got an unexpected keyword argument 'theta'"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "X,y = get_dataset(dataset_name)\n",
    "random_indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(random_indices)\n",
    "X = X[random_indices]\n",
    "y = y[random_indices]\n",
    "\n",
    "sub_groups_X = np.array_split(np.array(X), k_cross)\n",
    "sub_groups_y = np.array_split(np.array(y), k_cross) \n",
    "\n",
    "for k in range(k_cross):\n",
    "    X_train = np.concatenate(sub_groups_X[:k] + sub_groups_X[k+1:])\n",
    "    y_train = np.concatenate(sub_groups_y[:k] + sub_groups_y[k+1:])\n",
    "    X_test = sub_groups_X[k]\n",
    "    y_test = sub_groups_y[k]\n",
    "    for r in range(reps):\n",
    "        acc_bagging = evaluate_bagging(X_train, y_train, X_test, y_test)\n",
    "        accuracy, models, fitness = evaluate_bagging_sa(X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        result.append([k+1, r+1, fitness, accuracy, acc_bagging, acc_bagging_random])\n",
    "        print(f\"Fold {k+1:2}/{k_cross:2} | Rep {r+1:2}/{reps:2} | Fitness: {fitness:.3f} | Accuracy: {accuracy:.3f} | Bagging: {acc_bagging:.3f}, BaggingRandom: {acc_bagging_random:.3f}\")\n",
    "        df = pd.DataFrame(result, columns=['Fold', 'Rep', 'Fitness', 'Accuracy', 'Bagging', 'BaggingRandom'])\n",
    "        df.to_csv(f'./../res/test_bagging.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------+----------+---------+---------------+\n",
      "| Fold | Rep | Fitness | Accuracy | Bagging | BaggingRandom |\n",
      "+------+-----+---------+----------+---------+---------------+\n",
      "| 1.0  | 1.0 |  0.808  |  0.939   |  0.947  |     0.917     |\n",
      "| 1.0  | 2.0 |  0.808  |  0.933   |  0.947  |     0.95      |\n",
      "| 1.0  | 3.0 |  0.796  |  0.936   |  0.947  |     0.95      |\n",
      "| 1.0  | 4.0 |  0.796  |  0.942   |  0.947  |     0.936     |\n",
      "| 1.0  | 5.0 |   0.8   |   0.95   |  0.947  |     0.925     |\n",
      "| 2.0  | 1.0 |  0.796  |  0.961   |  0.947  |     0.944     |\n",
      "| 2.0  | 2.0 |  0.797  |   0.95   |  0.947  |     0.947     |\n",
      "| 2.0  | 3.0 |  0.797  |  0.958   |  0.947  |     0.947     |\n",
      "| 2.0  | 4.0 |  0.783  |  0.947   |  0.947  |     0.956     |\n",
      "| 2.0  | 5.0 |  0.798  |  0.958   |  0.947  |     0.956     |\n",
      "| 3.0  | 1.0 |  0.798  |  0.911   |  0.919  |     0.908     |\n",
      "| 3.0  | 2.0 |  0.787  |  0.897   |  0.919  |      0.9      |\n",
      "| 3.0  | 3.0 |  0.792  |  0.944   |  0.919  |     0.916     |\n",
      "| 3.0  | 4.0 |  0.818  |  0.933   |  0.919  |     0.886     |\n",
      "| 3.0  | 5.0 |  0.796  |  0.919   |  0.919  |     0.903     |\n",
      "| 4.0  | 1.0 |  0.788  |  0.928   |  0.916  |     0.939     |\n",
      "+------+-----+---------+----------+---------+---------------+\n",
      "Fitness mean:  0.797\n",
      "Accuracy mean: 0.938\n",
      "Bagging mean:  0.937\n",
      "Bagging Random mean:  0.930\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'./../res/test_bagging.csv')\n",
    "\n",
    "tmp = df.copy().round(3)\n",
    "print(tabulate(tmp, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "fitness_mean = df['Fitness'].mean()\n",
    "acc_mean = df['Accuracy'].mean()\n",
    "bagging_mean = df['Bagging'].mean()\n",
    "bagging_random_mean = df['BaggingRandom'].mean()\n",
    "\n",
    "print(f\"Fitness mean:  {fitness_mean:.3f}\")\n",
    "print(f\"Accuracy mean: {acc_mean:.3f}\")\n",
    "print(f\"Bagging mean:  {bagging_mean:.3f}\")\n",
    "print(f\"Bagging Random mean:  {bagging_random_mean:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    +------+-----+---------+----------+---------+---------------+\n",
    "    | Fold | Rep | Fitness | Accuracy | Bagging | BaggingRandom |\n",
    "    +------+-----+---------+----------+---------+---------------+\n",
    "    | 1.0  | 1.0 |  0.822  |  0.797   |  0.793  |     0.817     |\n",
    "    | 1.0  | 2.0 |  0.828  |  0.793   |  0.807  |     0.823     |\n",
    "    | 1.0  | 3.0 |  0.847  |  0.783   |  0.83   |     0.813     |\n",
    "    | 2.0  | 1.0 |  0.803  |  0.839   |  0.849  |     0.876     |\n",
    "    | 2.0  | 2.0 |  0.822  |  0.853   |  0.883  |     0.873     |\n",
    "    | 2.0  | 3.0 |  0.795  |  0.873   |  0.89   |     0.89      |\n",
    "    | 3.0  | 1.0 |  0.828  |  0.866   |  0.839  |     0.846     |\n",
    "    | 3.0  | 2.0 |  0.824  |  0.806   |  0.803  |     0.839     |\n",
    "    | 3.0  | 3.0 |  0.86   |  0.856   |  0.846  |     0.803     |\n",
    "    +------+-----+---------+----------+---------+---------------+\n",
    "    Fitness mean:  0.826\n",
    "    Accuracy mean: 0.830\n",
    "    Bagging mean:  0.838\n",
    "    Bagging Random mean:  0.842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro Bagging: t-statistic = 0.640, p-value = 0.000\n",
      "Shapiro BaggingSA: t-statistic = 0.941, p-value = 0.361\n",
      "Wilcoxon: w-statistic = 64.000, p-value = 0.235\n",
      "BaggingSA is not greater than Bagging\n"
     ]
    }
   ],
   "source": [
    "#statistic tests\n",
    "from scipy.stats import ttest_rel, wilcoxon, mannwhitneyu, shapiro\n",
    "\n",
    "t1_start, p1 = shapiro(df['Bagging'])\n",
    "t2_start, p2 = shapiro(df['Accuracy'])\n",
    "\n",
    "print(f\"Shapiro Bagging: t-statistic = {t1_start:.3f}, p-value = {p1:.3f}\")\n",
    "print(f\"Shapiro BaggingSA: t-statistic = {t2_start:.3f}, p-value = {p2:.3f}\")\n",
    "\n",
    "if p1 > 0.05 and p2 > 0.05:\n",
    "    t_stat, p_value = ttest_rel(df['Accuracy'], df['Bagging'], alternative='greater')\n",
    "    print(f\"t-test: t-statistic = {t_stat:.3f}, p-value = {p_value:.3f}\")\n",
    "    txt = 'BaggingSA is greater than Bagging' if p_value < 0.05 else 'BaggingSA is not greater than Bagging'\n",
    "    print(txt)\n",
    "else:\n",
    "    w_stat, p_value = wilcoxon(df['Accuracy'], df['Bagging'], alternative='greater')\n",
    "    print(f\"Wilcoxon: w-statistic = {w_stat:.3f}, p-value = {p_value:.3f}\")\n",
    "    txt = 'BaggingSA is greater than Bagging' if p_value < 0.05 else 'BaggingSA is not greater than Bagging'\n",
    "    print(txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
