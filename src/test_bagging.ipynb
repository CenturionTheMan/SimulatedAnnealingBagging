{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raw_python.Bagging import create_models, create_bags, evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from raw_python.BaggingSA import BaggingSA\n",
    "from raw_python.DatasetsHandle import get_dataset\n",
    "from tabulate import tabulate\n",
    "from raw_python.BaggingRandom import BaggingRandom\n",
    "\n",
    "seed = 41\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_name = 'digits'\n",
    "k_cross = 5\n",
    "reps = 5\n",
    "params = {\n",
    "    'T0': 2,\n",
    "    'cooling_method': 'geometric',\n",
    "    'alpha': 0.995,\n",
    "    'max_iterations': 2000,\n",
    "    'feature_mutation_chance': 0.25,\n",
    "    'test_split_amount': 5,\n",
    "    'theta': 0.85,\n",
    "    'beta': 0.1,\n",
    "    'gamma': 0.05,\n",
    "    'n_trees': 10,\n",
    "    'pop_size':1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "def evaluate_bagging(X_train, y_train, X_test, y_test):\n",
    "    n_trees = params['n_trees']\n",
    "    bags = create_bags(X_train, y_train, bags_amount=n_trees)\n",
    "    models = create_models(bags=bags)\n",
    "    accuracy = evaluate(X=X_test, y=y_test, models=models)\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_bagging_random(X_train, y_train, X_test, y_test):\n",
    "    n_trees = params['n_trees']\n",
    "    test_split_amount = params['test_split_amount']\n",
    "    pop_size = params['pop_size']\n",
    "    bagging_rand = BaggingRandom(X_train, y_train, n_trees, test_split_amount,pop_size)\n",
    "    models = bagging_rand.run()\n",
    "    accuracy = evaluate(X_test, y_test, models=models)\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "def evaluate_bagging_sa(X_train, y_train, X_test, y_test):\n",
    "    T0 = params['T0']\n",
    "    cooling_method = params['cooling_method']\n",
    "    alpha = params['alpha']\n",
    "    max_iterations = params['max_iterations']\n",
    "    feature_mutation_chance = params['feature_mutation_chance']\n",
    "    test_split_amount = params['test_split_amount']\n",
    "    n_trees = params['n_trees']\n",
    "    theta = params['theta']\n",
    "    beta = params['beta']\n",
    "    gamma = params['gamma']\n",
    "    bagging_sa = BaggingSA(X=X_train, y=y_train,\n",
    "                            T0=T0, cooling_method=cooling_method, alpha=alpha, max_iterations=max_iterations, n_trees=n_trees,\n",
    "                            feature_mutation_chance=feature_mutation_chance, test_split_amount=test_split_amount, theta=theta, beta=beta, gamma=gamma)\n",
    "    models, fitness = bagging_sa.run(X_for_test=X_test, y_for_test=y_test, monitor_fun=fun_monitor, get_fitness=True)\n",
    "    accuracy = evaluate(X_test, y_test, models=models)\n",
    "    return accuracy, models, fitness\n",
    "\n",
    "def fun_monitor(iteration, T, best_fitness, fitness, new_fitness, accuracy):\n",
    "    if accuracy is None:\n",
    "        accuracy = 0.0\n",
    "    # print(f\"    I: {iteration}, T: {T:.3f}, Best fitness: {best_fitness:.3f}, Fitness: {fitness:.3f}, New fitness: {new_fitness:.3f}, Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1/ 5 | Rep  1/ 5 | Fitness: 0.808 | Accuracy: 0.939 | Bagging: 0.947, BaggingRandom: 0.917\n",
      "Fold  1/ 5 | Rep  2/ 5 | Fitness: 0.808 | Accuracy: 0.933 | Bagging: 0.947, BaggingRandom: 0.950\n",
      "Fold  1/ 5 | Rep  3/ 5 | Fitness: 0.796 | Accuracy: 0.936 | Bagging: 0.947, BaggingRandom: 0.950\n",
      "Fold  1/ 5 | Rep  4/ 5 | Fitness: 0.796 | Accuracy: 0.942 | Bagging: 0.947, BaggingRandom: 0.936\n",
      "Fold  1/ 5 | Rep  5/ 5 | Fitness: 0.800 | Accuracy: 0.950 | Bagging: 0.947, BaggingRandom: 0.925\n",
      "Fold  2/ 5 | Rep  1/ 5 | Fitness: 0.796 | Accuracy: 0.961 | Bagging: 0.947, BaggingRandom: 0.944\n",
      "Fold  2/ 5 | Rep  2/ 5 | Fitness: 0.797 | Accuracy: 0.950 | Bagging: 0.947, BaggingRandom: 0.947\n",
      "Fold  2/ 5 | Rep  3/ 5 | Fitness: 0.797 | Accuracy: 0.958 | Bagging: 0.947, BaggingRandom: 0.947\n",
      "Fold  2/ 5 | Rep  4/ 5 | Fitness: 0.783 | Accuracy: 0.947 | Bagging: 0.947, BaggingRandom: 0.956\n",
      "Fold  2/ 5 | Rep  5/ 5 | Fitness: 0.798 | Accuracy: 0.958 | Bagging: 0.947, BaggingRandom: 0.956\n",
      "Fold  3/ 5 | Rep  1/ 5 | Fitness: 0.798 | Accuracy: 0.911 | Bagging: 0.919, BaggingRandom: 0.908\n",
      "Fold  3/ 5 | Rep  2/ 5 | Fitness: 0.787 | Accuracy: 0.897 | Bagging: 0.919, BaggingRandom: 0.900\n",
      "Fold  3/ 5 | Rep  3/ 5 | Fitness: 0.792 | Accuracy: 0.944 | Bagging: 0.919, BaggingRandom: 0.916\n",
      "Fold  3/ 5 | Rep  4/ 5 | Fitness: 0.818 | Accuracy: 0.933 | Bagging: 0.919, BaggingRandom: 0.886\n",
      "Fold  3/ 5 | Rep  5/ 5 | Fitness: 0.796 | Accuracy: 0.919 | Bagging: 0.919, BaggingRandom: 0.903\n",
      "Fold  4/ 5 | Rep  1/ 5 | Fitness: 0.788 | Accuracy: 0.928 | Bagging: 0.916, BaggingRandom: 0.939\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(reps):\n\u001b[32m     17\u001b[39m     acc_bagging = evaluate_bagging(X_train, y_train, X_test, y_test)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     acc_bagging_random = \u001b[43mevaluate_bagging_random\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     accuracy, models, fitness = evaluate_bagging_sa(X_train, y_train, X_test, y_test)\n\u001b[32m     21\u001b[39m     result.append([k+\u001b[32m1\u001b[39m, r+\u001b[32m1\u001b[39m, fitness, accuracy, acc_bagging, acc_bagging_random])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mevaluate_bagging_random\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test)\u001b[39m\n\u001b[32m     14\u001b[39m pop_size = params[\u001b[33m'\u001b[39m\u001b[33mpop_size\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     15\u001b[39m bagging_rand = BaggingRandom(X_train, y_train, n_trees, test_split_amount,pop_size)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m models = \u001b[43mbagging_rand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m accuracy = evaluate(X_test, y_test, models=models)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\src\\raw_python\\BaggingRandom.py:80\u001b[39m, in \u001b[36mBaggingRandom.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[BaggingModel]:\n\u001b[32m     79\u001b[39m     pop_bags = [create_bags(\u001b[38;5;28mself\u001b[39m.X_train, \u001b[38;5;28mself\u001b[39m.y_train, \u001b[38;5;28mself\u001b[39m.n_trees, replace=\u001b[38;5;28;01mTrue\u001b[39;00m, cut_features=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.pop_size)]\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     pop_models = [\u001b[43mcreate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbags\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m bags \u001b[38;5;129;01min\u001b[39;00m pop_bags]\n\u001b[32m     81\u001b[39m     pop_fit = [\u001b[38;5;28mself\u001b[39m.calculate_fitness(pop) \u001b[38;5;28;01mfor\u001b[39;00m pop \u001b[38;5;129;01min\u001b[39;00m pop_models]\n\u001b[32m     82\u001b[39m     best_pop = pop_models[np.argmax(pop_fit)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\src\\raw_python\\Bagging.py:103\u001b[39m, in \u001b[36mcreate_models\u001b[39m\u001b[34m(bags, n_jobs)\u001b[39m\n\u001b[32m     99\u001b[39m models = Parallel(n_jobs=n_jobs)(\n\u001b[32m    100\u001b[39m     delayed(create_model)(bag) \u001b[38;5;28;01mfor\u001b[39;00m bag \u001b[38;5;129;01min\u001b[39;00m bags\n\u001b[32m    101\u001b[39m )\n\u001b[32m    102\u001b[39m output_ratios = np.ones_like(models, dtype=\u001b[38;5;28mfloat\u001b[39m) / \u001b[38;5;28mlen\u001b[39m(models)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Ensemble(models=models, output_ratios=output_ratios)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "result = []\n",
    "X,y = get_dataset(dataset_name)\n",
    "random_indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(random_indices)\n",
    "X = X[random_indices]\n",
    "y = y[random_indices]\n",
    "\n",
    "sub_groups_X = np.array_split(np.array(X), k_cross)\n",
    "sub_groups_y = np.array_split(np.array(y), k_cross) \n",
    "\n",
    "for k in range(k_cross):\n",
    "    X_train = np.concatenate(sub_groups_X[:k] + sub_groups_X[k+1:])\n",
    "    y_train = np.concatenate(sub_groups_y[:k] + sub_groups_y[k+1:])\n",
    "    X_test = sub_groups_X[k]\n",
    "    y_test = sub_groups_y[k]\n",
    "    for r in range(reps):\n",
    "        acc_bagging = evaluate_bagging(X_train, y_train, X_test, y_test)\n",
    "        acc_bagging_random =-1# evaluate_bagging_random(X_train, y_train, X_test, y_test)\n",
    "        accuracy, models, fitness = evaluate_bagging_sa(X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        result.append([k+1, r+1, fitness, accuracy, acc_bagging, acc_bagging_random])\n",
    "        print(f\"Fold {k+1:2}/{k_cross:2} | Rep {r+1:2}/{reps:2} | Fitness: {fitness:.3f} | Accuracy: {accuracy:.3f} | Bagging: {acc_bagging:.3f}, BaggingRandom: {acc_bagging_random:.3f}\")\n",
    "        df = pd.DataFrame(result, columns=['Fold', 'Rep', 'Fitness', 'Accuracy', 'Bagging', 'BaggingRandom'])\n",
    "        df.to_csv(f'./../res/test_bagging.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------+----------+---------+---------------+\n",
      "| Fold | Rep | Fitness | Accuracy | Bagging | BaggingRandom |\n",
      "+------+-----+---------+----------+---------+---------------+\n",
      "| 1.0  | 1.0 |  0.808  |  0.939   |  0.947  |     0.917     |\n",
      "| 1.0  | 2.0 |  0.808  |  0.933   |  0.947  |     0.95      |\n",
      "| 1.0  | 3.0 |  0.796  |  0.936   |  0.947  |     0.95      |\n",
      "| 1.0  | 4.0 |  0.796  |  0.942   |  0.947  |     0.936     |\n",
      "| 1.0  | 5.0 |   0.8   |   0.95   |  0.947  |     0.925     |\n",
      "| 2.0  | 1.0 |  0.796  |  0.961   |  0.947  |     0.944     |\n",
      "| 2.0  | 2.0 |  0.797  |   0.95   |  0.947  |     0.947     |\n",
      "| 2.0  | 3.0 |  0.797  |  0.958   |  0.947  |     0.947     |\n",
      "| 2.0  | 4.0 |  0.783  |  0.947   |  0.947  |     0.956     |\n",
      "| 2.0  | 5.0 |  0.798  |  0.958   |  0.947  |     0.956     |\n",
      "| 3.0  | 1.0 |  0.798  |  0.911   |  0.919  |     0.908     |\n",
      "| 3.0  | 2.0 |  0.787  |  0.897   |  0.919  |      0.9      |\n",
      "| 3.0  | 3.0 |  0.792  |  0.944   |  0.919  |     0.916     |\n",
      "| 3.0  | 4.0 |  0.818  |  0.933   |  0.919  |     0.886     |\n",
      "| 3.0  | 5.0 |  0.796  |  0.919   |  0.919  |     0.903     |\n",
      "| 4.0  | 1.0 |  0.788  |  0.928   |  0.916  |     0.939     |\n",
      "+------+-----+---------+----------+---------+---------------+\n",
      "Fitness mean:  0.797\n",
      "Accuracy mean: 0.938\n",
      "Bagging mean:  0.937\n",
      "Bagging Random mean:  0.930\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'./../res/test_bagging.csv')\n",
    "\n",
    "tmp = df.copy().round(3)\n",
    "print(tabulate(tmp, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "fitness_mean = df['Fitness'].mean()\n",
    "acc_mean = df['Accuracy'].mean()\n",
    "bagging_mean = df['Bagging'].mean()\n",
    "bagging_random_mean = df['BaggingRandom'].mean()\n",
    "\n",
    "print(f\"Fitness mean:  {fitness_mean:.3f}\")\n",
    "print(f\"Accuracy mean: {acc_mean:.3f}\")\n",
    "print(f\"Bagging mean:  {bagging_mean:.3f}\")\n",
    "print(f\"Bagging Random mean:  {bagging_random_mean:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    +------+-----+---------+----------+---------+---------------+\n",
    "    | Fold | Rep | Fitness | Accuracy | Bagging | BaggingRandom |\n",
    "    +------+-----+---------+----------+---------+---------------+\n",
    "    | 1.0  | 1.0 |  0.822  |  0.797   |  0.793  |     0.817     |\n",
    "    | 1.0  | 2.0 |  0.828  |  0.793   |  0.807  |     0.823     |\n",
    "    | 1.0  | 3.0 |  0.847  |  0.783   |  0.83   |     0.813     |\n",
    "    | 2.0  | 1.0 |  0.803  |  0.839   |  0.849  |     0.876     |\n",
    "    | 2.0  | 2.0 |  0.822  |  0.853   |  0.883  |     0.873     |\n",
    "    | 2.0  | 3.0 |  0.795  |  0.873   |  0.89   |     0.89      |\n",
    "    | 3.0  | 1.0 |  0.828  |  0.866   |  0.839  |     0.846     |\n",
    "    | 3.0  | 2.0 |  0.824  |  0.806   |  0.803  |     0.839     |\n",
    "    | 3.0  | 3.0 |  0.86   |  0.856   |  0.846  |     0.803     |\n",
    "    +------+-----+---------+----------+---------+---------------+\n",
    "    Fitness mean:  0.826\n",
    "    Accuracy mean: 0.830\n",
    "    Bagging mean:  0.838\n",
    "    Bagging Random mean:  0.842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro Bagging: t-statistic = 0.640, p-value = 0.000\n",
      "Shapiro BaggingSA: t-statistic = 0.941, p-value = 0.361\n",
      "Wilcoxon: w-statistic = 64.000, p-value = 0.235\n",
      "BaggingSA is not greater than Bagging\n"
     ]
    }
   ],
   "source": [
    "#statistic tests\n",
    "from scipy.stats import ttest_rel, wilcoxon, mannwhitneyu, shapiro\n",
    "\n",
    "t1_start, p1 = shapiro(df['Bagging'])\n",
    "t2_start, p2 = shapiro(df['Accuracy'])\n",
    "\n",
    "print(f\"Shapiro Bagging: t-statistic = {t1_start:.3f}, p-value = {p1:.3f}\")\n",
    "print(f\"Shapiro BaggingSA: t-statistic = {t2_start:.3f}, p-value = {p2:.3f}\")\n",
    "\n",
    "if p1 > 0.05 and p2 > 0.05:\n",
    "    t_stat, p_value = ttest_rel(df['Accuracy'], df['Bagging'], alternative='greater')\n",
    "    print(f\"t-test: t-statistic = {t_stat:.3f}, p-value = {p_value:.3f}\")\n",
    "    txt = 'BaggingSA is greater than Bagging' if p_value < 0.05 else 'BaggingSA is not greater than Bagging'\n",
    "    print(txt)\n",
    "else:\n",
    "    w_stat, p_value = wilcoxon(df['Accuracy'], df['Bagging'], alternative='greater')\n",
    "    print(f\"Wilcoxon: w-statistic = {w_stat:.3f}, p-value = {p_value:.3f}\")\n",
    "    txt = 'BaggingSA is greater than Bagging' if p_value < 0.05 else 'BaggingSA is not greater than Bagging'\n",
    "    print(txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
