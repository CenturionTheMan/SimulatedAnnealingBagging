{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92a4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raw_python.Bagging import create_models, create_bags, evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from raw_python.BaggingSA import BaggingSA\n",
    "from typing import Literal, Tuple\n",
    "from raw_python.Bagging import predict\n",
    "import sklearn\n",
    "from scipy.stats import spearmanr, kendalltau, pearsonr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ad331",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "k_cross = 5\n",
    "test_split_amounts = [1, 5, 10] \n",
    "feature_mutation_chances = [0, .25, .5, .75, 1]\n",
    "datasets = ['digits','wine', 'breast_cancer', 'pima']\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7538a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_dataset(dataset_name: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    if dataset_name == 'digits':\n",
    "        data = sklearn.datasets.load_digits()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "        \n",
    "    elif dataset_name == 'wine':\n",
    "        data = sklearn.datasets.load_wine()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "    \n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = sklearn.datasets.load_breast_cancer()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "        \n",
    "    elif dataset_name == 'pima':\n",
    "        data = pd.read_csv(\"./../datasets/pima.csv\")\n",
    "        X = data.iloc[:, :-1].values\n",
    "        y = data.iloc[:, -1].values\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported dataset\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f1088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start at 2025-04-23 16:24:33.881956\n",
      "[Dataset: digits, split amount: 1, FMC: 0.25, k: 0]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9271\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9410\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9410\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9583\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9583\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9583\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9583\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9583\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9583\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9583\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9583\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9583\n",
      "    Accuracy: 0.9361\n",
      "[Dataset: digits, split amount: 1, FMC: 0.25, k: 1]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9410\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9410\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9410\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9479\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9479\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9549\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9549\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9549\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9549\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9549\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9653\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9653\n",
      "    Accuracy: 0.9417\n",
      "[Dataset: digits, split amount: 1, FMC: 0.25, k: 2]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9583\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9583\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9583\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9583\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9583\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9688\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9688\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9688\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9688\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9688\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9688\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9722\n",
      "    Accuracy: 0.9220\n",
      "[Dataset: digits, split amount: 1, FMC: 0.25, k: 3]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9375\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9410\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9410\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9410\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9410\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9410\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9410\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9444\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9444\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9444\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9583\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9583\n",
      "    Accuracy: 0.9248\n",
      "[Dataset: digits, split amount: 1, FMC: 0.25, k: 4]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9410\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9410\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9514\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9514\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9583\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9583\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9618\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9653\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9653\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9653\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9653\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9653\n",
      "    Accuracy: 0.9359\n",
      "[Dataset: digits, split amount: 1, FMC: 0.5, k: 0]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9444\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9444\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9549\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9549\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9549\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9549\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9583\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9653\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9653\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9653\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9653\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9653\n",
      "    Accuracy: 0.9556\n",
      "[Dataset: digits, split amount: 1, FMC: 0.5, k: 1]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9444\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9444\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9444\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9444\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9514\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9514\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9514\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9514\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9514\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9514\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9583\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9757\n",
      "    Accuracy: 0.9528\n",
      "[Dataset: digits, split amount: 1, FMC: 0.5, k: 2]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9688\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9722\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9722\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9722\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9722\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9722\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9722\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9757\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9792\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9792\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9792\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9792\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9792\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9792\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9792\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9792\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9792\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9792\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9792\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9792\n",
      "    Accuracy: 0.9192\n",
      "[Dataset: digits, split amount: 1, FMC: 0.5, k: 3]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9444\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9583\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9583\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9618\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9618\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9618\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9618\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9618\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9618\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9618\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9618\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9618\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9826\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9826\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9861\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9861\n",
      "    Accuracy: 0.9415\n",
      "[Dataset: digits, split amount: 1, FMC: 0.5, k: 4]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9583\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9618\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9618\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9618\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9618\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9618\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9688\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9757\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9757\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9757\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9757\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9757\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9757\n",
      "    Accuracy: 0.9331\n",
      "[Dataset: digits, split amount: 1, FMC: 0.75, k: 0]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9479\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9479\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9514\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9653\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9653\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9653\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9653\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9653\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9653\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9653\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9653\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9653\n",
      "    Accuracy: 0.9417\n",
      "[Dataset: digits, split amount: 1, FMC: 0.75, k: 1]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9618\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9618\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9618\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9618\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9618\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9618\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9618\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9618\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9618\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9618\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9618\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9618\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9618\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9653\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9722\n",
      "    Accuracy: 0.9500\n",
      "[Dataset: digits, split amount: 1, FMC: 0.75, k: 2]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9722\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9757\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9792\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9826\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9826\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9826\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9861\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9861\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9861\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9861\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9896\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9931\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9931\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9931\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9931\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9931\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9931\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9931\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9931\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9931\n",
      "    Accuracy: 0.9248\n",
      "[Dataset: digits, split amount: 1, FMC: 0.75, k: 3]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9479\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9479\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9514\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9514\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9514\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9514\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9583\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9583\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9583\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9583\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9583\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9583\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9618\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9618\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9618\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9618\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9618\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9618\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9618\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9618\n",
      "    Accuracy: 0.9499\n",
      "[Dataset: digits, split amount: 1, FMC: 0.75, k: 4]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9340\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9340\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9340\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9375\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9375\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9375\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9549\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9688\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9688\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9688\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9688\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9688\n",
      "    Accuracy: 0.9471\n",
      "[Dataset: digits, split amount: 5, FMC: 0.25, k: 0]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9514\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9514\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9515\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9515\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9515\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9583\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9583\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9688\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9688\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9688\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9688\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9688\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9722\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9722\n",
      "    Accuracy: 0.9444\n",
      "[Dataset: digits, split amount: 5, FMC: 0.25, k: 1]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9443\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9443\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9446\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9446\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9446\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9446\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9514\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9549\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9549\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9549\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9549\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9549\n",
      "    Iteration: 1300, T: 0.00, Best fitness: 0.9581\n",
      "    Iteration: 1400, T: 0.00, Best fitness: 0.9585\n",
      "    Iteration: 1500, T: 0.00, Best fitness: 0.9585\n",
      "    Iteration: 1600, T: 0.00, Best fitness: 0.9585\n",
      "    Iteration: 1700, T: 0.00, Best fitness: 0.9585\n",
      "    Iteration: 1800, T: 0.00, Best fitness: 0.9585\n",
      "    Iteration: 1900, T: 0.00, Best fitness: 0.9585\n",
      "    Iteration: 2000, T: 0.00, Best fitness: 0.9585\n",
      "    Accuracy: 0.9417\n",
      "[Dataset: digits, split amount: 5, FMC: 0.25, k: 2]\n",
      "    Iteration: 100, T: 1.22, Best fitness: 0.9513\n",
      "    Iteration: 200, T: 0.74, Best fitness: 0.9619\n",
      "    Iteration: 300, T: 0.45, Best fitness: 0.9619\n",
      "    Iteration: 400, T: 0.27, Best fitness: 0.9619\n",
      "    Iteration: 500, T: 0.16, Best fitness: 0.9619\n",
      "    Iteration: 600, T: 0.10, Best fitness: 0.9619\n",
      "    Iteration: 700, T: 0.06, Best fitness: 0.9619\n",
      "    Iteration: 800, T: 0.04, Best fitness: 0.9619\n",
      "    Iteration: 900, T: 0.02, Best fitness: 0.9619\n",
      "    Iteration: 1000, T: 0.01, Best fitness: 0.9619\n",
      "    Iteration: 1100, T: 0.01, Best fitness: 0.9619\n",
      "    Iteration: 1200, T: 0.00, Best fitness: 0.9619\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     50\u001b[39m fits = []\n\u001b[32m     51\u001b[39m accs = []\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m bagging_sa, accuracy, fitness = \u001b[43mevaluate_bagging_sa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_split_amount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m spearman_corr, spearman_p = spearmanr(fits, accs)\n\u001b[32m     57\u001b[39m acc_fitness_difference /= bagging_sa.max_iterations\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mevaluate_bagging_sa\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test, test_split_amount, feature_mutation_chance)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_bagging_sa\u001b[39m(X_train, y_train, X_test, y_test, test_split_amount, feature_mutation_chance) -> Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]: \n\u001b[32m      2\u001b[39m     bagging_sa = BaggingSA(X=X_train, y=y_train,\n\u001b[32m      3\u001b[39m                             T0=\u001b[32m2.0\u001b[39m, cooling_method=\u001b[33m'\u001b[39m\u001b[33mgeometric\u001b[39m\u001b[33m'\u001b[39m, alpha=\u001b[32m.995\u001b[39m, max_iterations=\u001b[32m2000\u001b[39m, n_trees=\u001b[32m10\u001b[39m,\n\u001b[32m      4\u001b[39m                             feature_mutation_chance=feature_mutation_chance, test_split_amount=test_split_amount)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     models, fitness = \u001b[43mbagging_sa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor_fun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfun_monitor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_fitness\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_for_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_for_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     accuracy = evaluate(X=X_test, y=y_test, models=models)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bagging_sa, accuracy, fitness\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\src\\raw_python\\BaggingSA.py:150\u001b[39m, in \u001b[36mBaggingSA.run\u001b[39m\u001b[34m(self, X_for_test, y_for_test, monitor_fun, get_fitness)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m iteration <= \u001b[38;5;28mself\u001b[39m.max_iterations \u001b[38;5;129;01mand\u001b[39;00m best_fitness < \u001b[32m1.0\u001b[39m:\n\u001b[32m    149\u001b[39m     new_bags = \u001b[38;5;28mself\u001b[39m.get_neighbors(bags)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     models = \u001b[43mcreate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_bags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     new_fitness = \u001b[38;5;28mself\u001b[39m.calculate_fitness(models)\n\u001b[32m    153\u001b[39m     accuracy = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\src\\raw_python\\Bagging.py:99\u001b[39m, in \u001b[36mcreate_models\u001b[39m\u001b[34m(bags, n_jobs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_models\u001b[39m(bags: List[Bag], n_jobs: \u001b[38;5;28mint\u001b[39m = -\u001b[32m1\u001b[39m) -> List[BaggingModel]:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbag\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbags\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_bagging_sa(X_train, y_train, X_test, y_test, test_split_amount, feature_mutation_chance) -> Tuple[float, int, int]: \n",
    "    bagging_sa = BaggingSA(X=X_train, y=y_train,\n",
    "                            T0=2.0, cooling_method='geometric', alpha=.995, max_iterations=2000, n_trees=10,\n",
    "                            feature_mutation_chance=feature_mutation_chance, test_split_amount=test_split_amount)\n",
    "    models, fitness = bagging_sa.run(monitor_fun=fun_monitor, get_fitness=True, X_for_test=X_test, y_for_test=y_test)\n",
    "    accuracy = evaluate(X=X_test, y=y_test, models=models)\n",
    "    return bagging_sa, accuracy, fitness\n",
    "    \n",
    "def fun_monitor(iteration, T, best_fitness, fitness, new_fitness, accuracy):\n",
    "    global fit_acc_sum, acc_fitness_difference\n",
    "    \n",
    "    acc_fitness_difference += abs(accuracy - fitness)\n",
    "    \n",
    "    fits.append(new_fitness)\n",
    "    accs.append(accuracy)\n",
    "\n",
    "    if iteration % 100 == 0:\n",
    "        print(f\"    Iteration: {iteration}, T: {T:.2f}, Best fitness: {best_fitness:.4f}\")\n",
    "\n",
    "acc_fitness_difference = 0.0\n",
    "fits = []\n",
    "accs = []\n",
    "result = []\n",
    "print(f\"Start at {pd.Timestamp.now()}\")\n",
    "for dataset in datasets:\n",
    "    X, y = get_dataset(dataset)       \n",
    "    \n",
    "    random_indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(random_indices)\n",
    "    X = X[random_indices]\n",
    "    y = y[random_indices]\n",
    "    \n",
    "    sub_groups_X = np.array_split(np.array(X), k_cross)\n",
    "    sub_groups_y = np.array_split(np.array(y), k_cross) \n",
    "         \n",
    "    for test_split_amount in test_split_amounts:\n",
    "        for fmc in feature_mutation_chances:\n",
    "            for k in range(k_cross):\n",
    "                print(f\"[Dataset: {dataset}, split amount: {test_split_amount}, FMC: {fmc}, k: {k}]\")\n",
    "                \n",
    "                if k_cross == 1:\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "                else:\n",
    "                    X_train = np.concatenate(sub_groups_X[:k] + sub_groups_X[k+1:])\n",
    "                    y_train = np.concatenate(sub_groups_y[:k] + sub_groups_y[k+1:])\n",
    "                    X_test = sub_groups_X[k]\n",
    "                    y_test = sub_groups_y[k]\n",
    "                \n",
    "                acc_fitness_difference = 0.0\n",
    "                fits = []\n",
    "                accs = []\n",
    "                \n",
    "                bagging_sa, accuracy, fitness = evaluate_bagging_sa(X_train, y_train, X_test, y_test, test_split_amount, fmc)\n",
    "                \n",
    "                spearman_corr, spearman_p = spearmanr(fits, accs)\n",
    "                \n",
    "                acc_fitness_difference /= bagging_sa.max_iterations\n",
    "                \n",
    "                result.append([dataset, k, test_split_amount, fmc, accuracy, spearman_corr, spearman_p, fitness, acc_fitness_difference])\n",
    "                \n",
    "                df = pd.DataFrame(result, columns=[\"dataset\", \"kCrossIndex\", \"test_split_amount\", \"fmc\", \"accuracy\", \"correlation\", \"spearmanP\", \"fitness\", \"accFitnessDifference\"])\n",
    "                df.to_csv(\"./../res/bagging_sa_params.csv\", index=False)\n",
    "                print(f\"    Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
