{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92a4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bagging import create_models, create_bags, evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from BaggingSA import BaggingSA\n",
    "from typing import Literal, Tuple\n",
    "from Bagging import predict\n",
    "import sklearn\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08ad331",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "k_cross = 10\n",
    "n_trees = [10]\n",
    "datasets = ['digits']\n",
    "\n",
    "bagging_sa_params = {\n",
    "    'digits' : {\n",
    "        'T0': 2,\n",
    "        'cooling_method': 'geometric',\n",
    "        'alpha': 0.995,\n",
    "        'max_iterations': 2000,\n",
    "        'feature_mutation_chance': 0.3,\n",
    "        'test_split_amount': 10        \n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7538a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_name: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    if dataset_name == 'digits':\n",
    "        data = sklearn.datasets.load_digits()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "        \n",
    "    elif dataset_name == 'wine':\n",
    "        data = sklearn.datasets.load_wine()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "    \n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = sklearn.datasets.load_breast_cancer()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "        \n",
    "    elif dataset_name == 'pima':\n",
    "        data = pd.read_csv(\"./../datasets/pima.csv\")\n",
    "        X = data.iloc[:, :-1].values\n",
    "        y = data.iloc[:, -1].values\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported dataset\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f1088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start at 2025-04-22 14:47:32.736305\n",
      "    Dataset: digits, n_trees: 10, k: 1/10 >> Bagging LIB: 0.9333, Bagging: 0.9278, Bagging SA: 0.0000\n",
      "    Dataset: digits, n_trees: 10, k: 2/10 >> Bagging LIB: 0.9556, Bagging: 0.9611, Bagging SA: 0.0000\n",
      "    Dataset: digits, n_trees: 10, k: 3/10 >> Bagging LIB: 0.9333, Bagging: 0.9333, Bagging SA: 0.0000\n",
      "    Dataset: digits, n_trees: 10, k: 4/10 >> Bagging LIB: 0.9333, Bagging: 0.9056, Bagging SA: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     63\u001b[39m y_test = sub_groups_y[k]\n\u001b[32m     65\u001b[39m dt_acc, dt_correct, dt_wrong = evaluate_bagging_lib(X_train, y_train, X_test, y_test, n_trees=n_tree)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m bagging_acc, bagging_correct, bagging_wrong = \u001b[43mevaluate_bagging\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trees\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_tree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m pars = bagging_sa_params[dataset]\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m#bagging_sa_acc, bagging_sa_correct, bagging_sa_wrong = evaluate_bagging_sa(X_train, y_train, X_test, y_test, n_trees=n_tree, params=pars)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mevaluate_bagging\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test, n_trees)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_bagging\u001b[39m(X_train, y_train, X_test, y_test, n_trees: \u001b[38;5;28mint\u001b[39m) -> Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m     30\u001b[39m     bags = create_bags(X_train, y_train, bags_amount=n_trees, replace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     models = \u001b[43mcreate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     predictions = predict(X=X_test, models=models)\n\u001b[32m     33\u001b[39m     accuracy, correct_pred_amount, wrong_pred_amount = get_measures(predictions, y_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\src\\Bagging.py:80\u001b[39m, in \u001b[36mcreate_models\u001b[39m\u001b[34m(bags)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_models\u001b[39m(bags: List[Bag]) -> List[BaggingModel]:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     models = [\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbag\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m bag \u001b[38;5;129;01min\u001b[39;00m bags]\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\src\\Bagging.py:76\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(bag)\u001b[39m\n\u001b[32m     74\u001b[39m X_mapped, y_mapped = bag.X, bag.y\n\u001b[32m     75\u001b[39m model = DecisionTreeClassifier()\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_mapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaggingModel(model, bag)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1024\u001b[39m, in \u001b[36mDecisionTreeClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, check_input=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    995\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[32m    996\u001b[39m \n\u001b[32m    997\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1021\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1022\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def get_measures(predictions, y_test):\n",
    "    correct_pred_amount = 0\n",
    "    wrong_pred_amount = 0\n",
    "    accuracy = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == y_test[i]:\n",
    "            correct_pred_amount += 1\n",
    "        else:\n",
    "            wrong_pred_amount += 1\n",
    "    accuracy = correct_pred_amount / (correct_pred_amount + wrong_pred_amount)\n",
    "    return accuracy, correct_pred_amount, wrong_pred_amount\n",
    "    \n",
    "def evaluate_bagging_sa(X_train, y_train, X_test, y_test, n_trees: int, params: dict) -> Tuple[float, int, int]: \n",
    "    T0 = params['T0']\n",
    "    cooling_method = params['cooling_method']\n",
    "    alpha = params['alpha']\n",
    "    max_iterations = params['max_iterations']\n",
    "    feature_mutation_chance = params['feature_mutation_chance']\n",
    "    test_split_amount = params['test_split_amount']\n",
    "    bagging_sa = BaggingSA(X=X_train, y=y_train,\n",
    "                            T0=T0, cooling_method=cooling_method, alpha=alpha, max_iterations=max_iterations, n_trees=n_trees,\n",
    "                            feature_mutation_chance=feature_mutation_chance, test_split_amount=test_split_amount)\n",
    "    models = bagging_sa.run()\n",
    "    predictions = predict(X=X_test, models=models)\n",
    "    accuracy, correct_pred_amount, wrong_pred_amount = get_measures(predictions, y_test)\n",
    "    return accuracy, correct_pred_amount, wrong_pred_amount\n",
    "\n",
    "\n",
    "def evaluate_bagging(X_train, y_train, X_test, y_test, n_trees: int) -> Tuple[float, int, int]:\n",
    "    bags = create_bags(X_train, y_train, bags_amount=n_trees, replace=True)\n",
    "    models = create_models(bags=bags)\n",
    "    predictions = predict(X=X_test, models=models)\n",
    "    accuracy, correct_pred_amount, wrong_pred_amount = get_measures(predictions, y_test)\n",
    "    return accuracy, correct_pred_amount, wrong_pred_amount\n",
    "  \n",
    "    \n",
    "def evaluate_bagging_lib(X_train, y_train, X_test, y_test, n_trees: int):\n",
    "    model = BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=None, min_samples_split=2), n_estimators=n_trees, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy, correct_pred_amount, wrong_pred_amount = get_measures(y_pred, y_test)\n",
    "    return accuracy, correct_pred_amount, wrong_pred_amount\n",
    "\n",
    "\n",
    "result = []\n",
    "print(f\"Start at {pd.Timestamp.now()}\")\n",
    "for dataset in datasets:\n",
    "    X, y = get_dataset(dataset)       \n",
    "    \n",
    "    random_indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(random_indices)\n",
    "    X = X[random_indices]\n",
    "    y = y[random_indices]\n",
    "    \n",
    "    sub_groups_X = np.array_split(np.array(X), k_cross)\n",
    "    sub_groups_y = np.array_split(np.array(y), k_cross) \n",
    "         \n",
    "    for n_tree in n_trees:\n",
    "        for k in range(k_cross):\n",
    "            X_train = np.concatenate(sub_groups_X[:k] + sub_groups_X[k+1:])\n",
    "            y_train = np.concatenate(sub_groups_y[:k] + sub_groups_y[k+1:])\n",
    "            X_test = sub_groups_X[k]\n",
    "            y_test = sub_groups_y[k]\n",
    "            \n",
    "            dt_acc, dt_correct, dt_wrong = evaluate_bagging_lib(X_train, y_train, X_test, y_test, n_trees=n_tree)\n",
    "            bagging_acc, bagging_correct, bagging_wrong = evaluate_bagging(X_train, y_train, X_test, y_test, n_trees=n_tree)\n",
    "            \n",
    "            pars = bagging_sa_params[dataset]\n",
    "            #bagging_sa_acc, bagging_sa_correct, bagging_sa_wrong = evaluate_bagging_sa(X_train, y_train, X_test, y_test, n_trees=n_tree, params=pars)\n",
    "            bagging_sa_acc, bagging_sa_correct, bagging_sa_wrong = 0,0,0\n",
    "            print(f\"    Dataset: {dataset}, n_trees: {n_tree}, k: {k+1}/{k_cross} >> Bagging LIB: {dt_acc:.4f}, Bagging: {bagging_acc:.4f}, Bagging SA: {bagging_sa_acc:.4f}\")\n",
    "            result.append([dt_acc, bagging_acc, bagging_sa_acc])\n",
    "    \n",
    "    df = pd.DataFrame(data=result, columns=[\"Bagging LIB\", \"Bagging\", \"Bagging SA\"])\n",
    "    print(f\"BaggingLIB={df['Bagging LIB'].mean():.3f} | Bagging={df['Bagging'].mean():.3f} | BaggingSA={df['Bagging SA'].mean():.3f}\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
