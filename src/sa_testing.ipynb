{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "seed = 42\n",
    "bags_amount = 10\n",
    "bag_size_ratio = 0.7\n",
    "\n",
    "t0 = 10\n",
    "alpha = 0.1\n",
    "max_iter = 100\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_bag(\n",
    "    data: Tuple[np.ndarray, np.ndarray],\n",
    "    bag_size_ratio: float = 0.7) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \n",
    "    X, y = data\n",
    "    bag_size = int(len(X) * bag_size_ratio)\n",
    "    idx = np.random.choice(len(X), bag_size, replace=True)\n",
    "    tmpX, tmpy = X[idx], y[idx]\n",
    "\n",
    "    # Add randomness to feature selection\n",
    "    min_features = max(2, int(np.sqrt(X.shape[1]) * 0.8))  # Ensure at least 2 features\n",
    "    max_features = min(X.shape[1], int(np.sqrt(X.shape[1]) * 1.2))  \n",
    "    features_amount = np.random.randint(min_features, max_features + 1)  \n",
    "\n",
    "    features_idx = np.random.choice(X.shape[1], features_amount, replace=False)\n",
    "    return tmpX[:, features_idx], tmpy, features_idx  # Return selected features too\n",
    "\n",
    "    \n",
    "def get_neighbor_bag(\n",
    "    data: Tuple[np.ndarray, np.ndarray],\n",
    "    bag: Tuple[np.ndarray, np.ndarray, np.ndarray]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "\n",
    "    X, y = data\n",
    "    X_bag, y_bag, features_idx = bag  \n",
    "    \n",
    "    new_X_bag = np.copy(X_bag)\n",
    "    new_y_bag = np.copy(y_bag)\n",
    "\n",
    "    num_swaps = max(1, len(X_bag) // 10)\n",
    "    for _ in range(num_swaps):\n",
    "        index_from = random.randint(0, len(new_X_bag) - 1)\n",
    "        index_to = random.randint(0, len(X) - 1)\n",
    "\n",
    "        new_X_bag[index_from] = X[index_to, features_idx]\n",
    "        new_y_bag[index_from] = y[index_to]\n",
    "\n",
    "    return new_X_bag, new_y_bag, features_idx\n",
    "\n",
    "\n",
    "\n",
    "def create_model(\n",
    "    bag: Tuple[np.ndarray, np.ndarray, np.ndarray]) -> Tuple[DecisionTreeClassifier, np.ndarray]:\n",
    "    X, y, features_idx = bag\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X, y)\n",
    "    return clf, features_idx\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    clf: DecisionTreeClassifier,\n",
    "    data: Tuple[np.ndarray, np.ndarray]) -> float:\n",
    "    X, y = data\n",
    "    y_pred = clf.predict(X)\n",
    "    return accuracy_score(y, y_pred)\n",
    "\n",
    "def evaluate_ensemble(\n",
    "    clfs: list[Tuple[DecisionTreeClassifier, np.ndarray]],\n",
    "    data: Tuple[np.ndarray, np.ndarray]) -> float:\n",
    "    X, y = data\n",
    "    y_pred = np.zeros(len(y))\n",
    "\n",
    "    for clf, features_idx in clfs:\n",
    "        sub_X = X[:, features_idx]\n",
    "        y_pred += clf.predict(sub_X)\n",
    "\n",
    "    y_pred = [1 if x > len(clfs) / 2 else 0 for x in y_pred]\n",
    "    return accuracy_score(y, y_pred)\n",
    "\n",
    "\n",
    "def get_new_temperature(\n",
    "    t: float,\n",
    "    alpha: float) -> float:\n",
    "    return t * (1 - alpha)\n",
    "\n",
    "def get_acceptance_probability(delta_fitness:float ,t: float) -> float:\n",
    "    return np.exp(-delta_fitness / t)\n",
    "\n",
    "def SA_Bagging(\n",
    "    data: Tuple[np.ndarray, np.ndarray],\n",
    "    bags_amount: int, \n",
    "    bag_size_ratio: float, \n",
    "    t0: float, \n",
    "    alpha: float, \n",
    "    max_iter: int) -> np.ndarray:\n",
    "    \n",
    "    cur_temp = t0\n",
    "    cur_iter = 0\n",
    "    cur_bags = [create_random_bag(data, bag_size_ratio) for _ in range(bags_amount)]\n",
    "    models = [create_model(bag) for bag in cur_bags]\n",
    "    cur_fitness = evaluate_ensemble(models, data)\n",
    "    \n",
    "    best_bags = cur_bags.copy()\n",
    "    best_fitness = cur_fitness\n",
    "    \n",
    "    print(f\"Initial fitness: {cur_fitness}\")\n",
    "    \n",
    "    while cur_iter < max_iter:\n",
    "        new_bags = [get_neighbor_bag(data, bag) for bag in cur_bags]\n",
    "        new_models = [create_model(bag) for bag in new_bags]\n",
    "        new_fitness = evaluate_ensemble(new_models, data)\n",
    "        delta_fitness = new_fitness - cur_fitness\n",
    "\n",
    "\n",
    "        if new_fitness > best_fitness:\n",
    "            best_bags = new_bags\n",
    "            best_fitness = new_fitness\n",
    "\n",
    "        if delta_fitness > 0 or get_acceptance_probability(delta_fitness, cur_temp) > random.random():\n",
    "            cur_bags = new_bags\n",
    "            cur_fitness = new_fitness\n",
    "\n",
    "\n",
    "        print(f\"Iteration: {cur_iter}, Fitness: {cur_fitness}, Best fitness: {best_fitness}\")\n",
    "        cur_temp = get_new_temperature(cur_temp, alpha)\n",
    "        cur_iter += 1\n",
    "\n",
    "        \n",
    "    print(f\"Best fitness: {best_fitness}\")\n",
    "    return best_bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial fitness: 0.6476190476190476\n",
      "Iteration: 0, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 1, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 2, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 3, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 4, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 5, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 6, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 7, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 8, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 9, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 10, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 11, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 12, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 13, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 14, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 15, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 16, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 17, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 18, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 19, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 20, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 21, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 22, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 23, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 24, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 25, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 26, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 27, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 28, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 29, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 30, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 31, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 32, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 33, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 34, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 35, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 36, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 37, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 38, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 39, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 40, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 41, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 42, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 43, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 44, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 45, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 46, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 47, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 48, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 49, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 50, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 51, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 52, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 53, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 54, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 55, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 56, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 57, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 58, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 59, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 60, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 61, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 62, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 63, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 64, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 65, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 66, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 67, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 68, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 69, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 70, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 71, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 72, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 73, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 74, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 75, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 76, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 77, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 78, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 79, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 80, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 81, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 82, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 83, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 84, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 85, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 86, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 87, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 88, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 89, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 90, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 91, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 92, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 93, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 94, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 95, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 96, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 97, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 98, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Iteration: 99, Fitness: 0.6476190476190476, Best fitness: 0.6476190476190476\n",
      "Best fitness: 0.6476190476190476\n",
      "Accuracy: 0.7111111111111111\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "train_data = (X_train, y_train)\n",
    "test_data = (X_test, y_test)\n",
    "\n",
    "best_bags = SA_Bagging(train_data, bags_amount, bag_size_ratio, t0, alpha, max_iter)\n",
    "\n",
    "best_models = [create_model(bag) for bag in best_bags]\n",
    "accuracy = evaluate_ensemble(best_models, test_data)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "train_data = (X_train, y_train)\n",
    "test_data = (X_test, y_test)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
