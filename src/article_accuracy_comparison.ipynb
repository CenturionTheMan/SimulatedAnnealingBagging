{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d92a4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from raw_python.BaggingSA import BaggingSA\n",
    "from typing import Literal, Tuple\n",
    "import sklearn\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from raw_python.Bagging import create_models, create_bags, evaluate, predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08ad331",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m      5\u001b[39m datasets = [\u001b[33m'\u001b[39m\u001b[33mdigits\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwine\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbreast_cancer\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpima\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m bagging_sa_params = {\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mwine\u001b[39m\u001b[33m'\u001b[39m : {\n\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mT0\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m \n\u001b[32m     42\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43mnp\u001b[49m.random.seed(seed)\n\u001b[32m     45\u001b[39m random.seed(seed)\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "k_cross = 5\n",
    "n_trees = [10, 20, 30, 40, 50]\n",
    "datasets = ['digits', 'wine', 'breast_cancer', 'pima']\n",
    "\n",
    "bagging_sa_params = {\n",
    "    'wine' : {\n",
    "        'T0': 2,\n",
    "        'cooling_method': 'geometric',\n",
    "        'alpha': 0.995,\n",
    "        'max_iterations': 2000,\n",
    "        'feature_mutation_chance': 0.2,\n",
    "        'test_split_amount': 5        \n",
    "    },\n",
    "    'breast_cancer' : {\n",
    "        'T0': 2,\n",
    "        'cooling_method': 'geometric',\n",
    "        'alpha': 0.995,\n",
    "        'max_iterations': 2000,\n",
    "        'feature_mutation_chance': 0.2,\n",
    "        'test_split_amount': 5        \n",
    "    },\n",
    "    'pima' : {\n",
    "        'T0': 2,\n",
    "        'cooling_method': 'geometric',\n",
    "        'alpha': 0.995,\n",
    "        'max_iterations': 2000,\n",
    "        'feature_mutation_chance': 0.2,\n",
    "        'test_split_amount': 5        \n",
    "    },\n",
    "    \n",
    "    'digits' : {\n",
    "        'T0': 2,\n",
    "        'cooling_method': 'geometric',\n",
    "        'alpha': 0.995,\n",
    "        'max_iterations': 2000,\n",
    "        'feature_mutation_chance': 0.2,\n",
    "        'test_split_amount': 5        \n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7538a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_name: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    if dataset_name == 'digits':\n",
    "        data = sklearn.datasets.load_digits()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "        \n",
    "    elif dataset_name == 'wine':\n",
    "        data = sklearn.datasets.load_wine()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "    \n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = sklearn.datasets.load_breast_cancer()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "        \n",
    "    elif dataset_name == 'pima':\n",
    "        data = pd.read_csv(\"./../datasets/pima.csv\")\n",
    "        X = data.iloc[:, :-1].values\n",
    "        y = data.iloc[:, -1].values\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported dataset\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start at 2025-04-22 16:38:10.486131\n",
      "    Dataset: digits, n_trees: 10, k: 1/10 >> DT: 0.8833, Bagging: 0.9333, RF: 0.9500, BaggingCustom: 0.9333, BaggingSA: 0.9778\n",
      "    Dataset: digits, n_trees: 10, k: 2/10 >> DT: 0.8333, Bagging: 0.9556, RF: 0.9611, BaggingCustom: 0.9556, BaggingSA: 0.9556\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     66\u001b[39m rf_acc = evaluate_rf(X_train, y_train, X_test, y_test, n_trees=n_tree)\n\u001b[32m     67\u001b[39m bagging_custom_acc = evaluate_bagging(X_train, y_train, X_test, y_test, n_trees=n_tree)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m bagging_sa_acc = \u001b[43mevaluate_bagging_sa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trees\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, n_trees: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_tree\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, k: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_cross\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m >> DT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Bagging: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbagging_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, RF: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, BaggingCustom: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbagging_custom_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, BaggingSA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbagging_sa_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m result.append([\n\u001b[32m     73\u001b[39m     dataset, n_tree, k+\u001b[32m1\u001b[39m, dt_acc, bagging_acc, rf_acc, bagging_custom_acc, bagging_sa_acc\n\u001b[32m     74\u001b[39m ])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mevaluate_bagging_sa\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test, n_trees, params)\u001b[39m\n\u001b[32m     21\u001b[39m test_split_amount = params[\u001b[33m'\u001b[39m\u001b[33mtest_split_amount\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     22\u001b[39m bagging_sa = BaggingSA(X=X_train, y=y_train,\n\u001b[32m     23\u001b[39m                         T0=T0, cooling_method=cooling_method, alpha=alpha, max_iterations=max_iterations, n_trees=n_trees,\n\u001b[32m     24\u001b[39m                         feature_mutation_chance=feature_mutation_chance, test_split_amount=test_split_amount)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m models = \u001b[43mbagging_sa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m accuracy = evaluate(X=X_test, y=y_test, models=models)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/SimulatedAnnealingBagging/src/BaggingSA.py:150\u001b[39m, in \u001b[36mBaggingSA.run\u001b[39m\u001b[34m(self, X_for_test, y_for_test, monitor_fun, get_fitness)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m T > \u001b[32m1e-10\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m iteration <= \u001b[38;5;28mself\u001b[39m.max_iterations \u001b[38;5;129;01mand\u001b[39;00m best_fitness < \u001b[32m1.0\u001b[39m:\n\u001b[32m    149\u001b[39m     new_bags = \u001b[38;5;28mself\u001b[39m.get_neighbors(bags)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     models = \u001b[43mcreate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_bags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     new_fitness = \u001b[38;5;28mself\u001b[39m.calculate_fitness(models)\n\u001b[32m    153\u001b[39m     accuracy = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/SimulatedAnnealingBagging/src/Bagging.py:86\u001b[39m, in \u001b[36mcreate_models\u001b[39m\u001b[34m(bags)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_models\u001b[39m(bags: List[Bag]) -> List[BaggingModel]:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     models = [\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbag\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m bag \u001b[38;5;129;01min\u001b[39;00m bags]\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/SimulatedAnnealingBagging/src/Bagging.py:82\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(bag)\u001b[39m\n\u001b[32m     80\u001b[39m X_mapped, y_mapped = bag.get_mapped_data()\n\u001b[32m     81\u001b[39m model = DecisionTreeClassifier()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_mapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaggingModel(model, bag)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/SimulatedAnnealingBagging/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/SimulatedAnnealingBagging/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:1024\u001b[39m, in \u001b[36mDecisionTreeClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, check_input=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    995\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[32m    996\u001b[39m \n\u001b[32m    997\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1021\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1022\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/SimulatedAnnealingBagging/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def evaluate_rf(X_train, y_train, X_test, y_test, n_trees: int) -> float:\n",
    "    model = RandomForestClassifier(n_estimators=n_trees, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_bagging_custom(X_train, y_train, X_test, y_test, n_trees: int) -> float:\n",
    "    bags = create_bags(X_train, y_train, bags_amount=n_trees)\n",
    "    models = create_models(bags=bags)\n",
    "    accuracy = evaluate(X=X_test, y=y_test, models=models)\n",
    "    return accuracy\n",
    "  \n",
    "    \n",
    "def evaluate_bagging_sa(X_train, y_train, X_test, y_test, n_trees: int, params: dict) -> float:\n",
    "    T0 = params['T0']\n",
    "    cooling_method = params['cooling_method']\n",
    "    alpha = params['alpha']\n",
    "    max_iterations = params['max_iterations']\n",
    "    feature_mutation_chance = params['feature_mutation_chance']\n",
    "    test_split_amount = params['test_split_amount']\n",
    "    bagging_sa = BaggingSA(X=X_train, y=y_train,\n",
    "                            T0=T0, cooling_method=cooling_method, alpha=alpha, max_iterations=max_iterations, n_trees=n_trees,\n",
    "                            feature_mutation_chance=feature_mutation_chance, test_split_amount=test_split_amount)\n",
    "    models = bagging_sa.run()\n",
    "    accuracy = evaluate(X=X_test, y=y_test, models=models)\n",
    "    return accuracy\n",
    "    \n",
    "    \n",
    "def evaluate_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_bagging(X_train, y_train, X_test, y_test, n_trees: int) -> float:\n",
    "    model = BaggingClassifier(n_estimators=n_trees, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy    \n",
    "\n",
    "result = []\n",
    "print(f\"Start at {pd.Timestamp.now()}\")\n",
    "for dataset in datasets:\n",
    "    X, y = get_dataset(dataset)       \n",
    "    \n",
    "    random_indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(random_indices)\n",
    "    X = X[random_indices]\n",
    "    y = y[random_indices]\n",
    "    \n",
    "    sub_groups_X = np.array_split(np.array(X), k_cross)\n",
    "    sub_groups_y = np.array_split(np.array(y), k_cross) \n",
    "         \n",
    "    for n_tree in n_trees:\n",
    "        for k in range(k_cross):\n",
    "            X_train = np.concatenate(sub_groups_X[:k] + sub_groups_X[k+1:])\n",
    "            y_train = np.concatenate(sub_groups_y[:k] + sub_groups_y[k+1:])\n",
    "            X_test = sub_groups_X[k]\n",
    "            y_test = sub_groups_y[k]\n",
    "            pars = bagging_sa_params[dataset]\n",
    "            \n",
    "            dt_acc= evaluate_decision_tree(X_train, y_train, X_test, y_test)\n",
    "            bagging_acc = evaluate_bagging(X_train, y_train, X_test, y_test, n_trees=n_tree)\n",
    "            rf_acc = evaluate_rf(X_train, y_train, X_test, y_test, n_trees=n_tree)\n",
    "            bagging_custom_acc = evaluate_bagging_custom(X_train, y_train, X_test, y_test, n_trees=n_tree)\n",
    "            bagging_sa_acc = evaluate_bagging_sa(X_train, y_train, X_test, y_test, n_trees=n_tree, params=pars)\n",
    "            \n",
    "            print(f\"    Dataset: {dataset}, n_trees: {n_tree}, k: {k+1}/{k_cross} >> DT: {dt_acc:.4f}, Bagging: {bagging_acc:.4f}, RF: {rf_acc:.4f}, BaggingCustom: {bagging_custom_acc:.4f}, BaggingSA: {bagging_sa_acc:.4f}\")\n",
    "            \n",
    "            result.append([\n",
    "                dataset, n_tree, k+1, dt_acc, bagging_acc, rf_acc, bagging_custom_acc, bagging_sa_acc\n",
    "            ])\n",
    "            \n",
    "            df = pd.DataFrame(result, columns=[\n",
    "                \"Dataset\",\n",
    "                \"nTrees\",\n",
    "                \"K\",\n",
    "                \"DT\",\n",
    "                \"Bagging\",\n",
    "                \"RF\",\n",
    "                \"BaggingCustom\",\n",
    "                \"BaggingSA\"\n",
    "            ])\n",
    "            \n",
    "            df.to_csv(f'./../res/accuracy_comparison_{dataset}.csv', index=False)                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
