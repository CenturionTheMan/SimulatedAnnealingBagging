{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92a4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bagging import create_models, create_bags, evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from BaggingSA import BaggingSA\n",
    "from typing import Literal, Tuple\n",
    "from Bagging import predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ad331",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "k_cross = 10\n",
    "n_trees = [10, 20, 30, 40, 50]\n",
    "datasets = ['wine', 'abalone', 'breast_cancer', 'pima', 'digits']\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7538a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "\n",
    "def get_dataset(dataset_name: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    if dataset_name == 'digits':\n",
    "        data = sklearn.datasets.load_digits()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "        \n",
    "    elif dataset_name == 'wine':\n",
    "        data = sklearn.datasets.load_wine()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "    \n",
    "    elif dataset_name == 'abalone':\n",
    "        column_names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\", \n",
    "                \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "        data = pd.read_csv(\"./../datasets/abalone.data\", names=column_names)\n",
    "        for label in \"MFI\":\n",
    "            data[label] = data[\"sex\"] == label\n",
    "        del data[\"sex\"]\n",
    "        y = data.rings.values\n",
    "        del data[\"rings\"]\n",
    "        X = data.values.astype(float)\n",
    "    \n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = sklearn.datasets.load_breast_cancer()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "        \n",
    "    elif dataset_name == 'pima':\n",
    "        data = pd.read_csv(\"./../datasets/pima.csv\")\n",
    "        X = data.iloc[:, :-1].values\n",
    "        y = data.iloc[:, -1].values\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported dataset\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start at 2025-04-14 11:35:41.045230\n",
      "Dataset: pima, n_trees: 10, k: 0/10 >> DT: 0.6623, Bagging: 0.5844, BaggingSA: 0.6494\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m dt_acc, dt_correct, dt_wrong = evaluate_decision_tree(X_train, y_train, X_test, y_test)\n\u001b[32m     54\u001b[39m bagging_acc, bagging_correct, bagging_wrong = evaluate_bagging(X_train, y_train, X_test, y_test, n_trees=n_tree)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m bagging_sa_acc, bagging_sa_correct, bagging_sa_wrong = \u001b[43mevaluate_bagging_sa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trees\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_tree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, n_trees: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_tree\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, k: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_cross\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m >> DT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Bagging: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbagging_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, BaggingSA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbagging_sa_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m result.append([\n\u001b[32m     60\u001b[39m     dataset, n_tree, k, dt_acc, bagging_acc, bagging_sa_acc,\n\u001b[32m     61\u001b[39m     dt_correct, bagging_correct, bagging_sa_correct,\n\u001b[32m     62\u001b[39m     dt_wrong, bagging_wrong, bagging_sa_wrong\n\u001b[32m     63\u001b[39m ])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mevaluate_bagging_sa\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test, n_trees)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_bagging_sa\u001b[39m(X_train, y_train, X_test, y_test, n_trees: \u001b[38;5;28mint\u001b[39m) -> Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]: \n\u001b[32m     22\u001b[39m     bagging_sa = BaggingSA(X=X_train, y=y_train,\n\u001b[32m     23\u001b[39m                             T0=\u001b[32m10\u001b[39m, cooling_method=\u001b[33m'\u001b[39m\u001b[33mgeometric\u001b[39m\u001b[33m'\u001b[39m, alpha=\u001b[32m0.99\u001b[39m, max_iterations=\u001b[32m3000\u001b[39m, n_trees=n_trees,\n\u001b[32m     24\u001b[39m                             fitness_accuracy_disagreement_ratio=\u001b[32m0.8\u001b[39m,\n\u001b[32m     25\u001b[39m                             feature_mutation_chance=\u001b[32m0.3\u001b[39m, test_split_amount=\u001b[32m20\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     models = \u001b[43mbagging_sa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     predictions = predict(X=X_test, models=models)\n\u001b[32m     28\u001b[39m     accuracy, correct_pred_amount, wrong_pred_amount = get_measures(predictions, y_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\src\\BaggingSA.py:142\u001b[39m, in \u001b[36mBaggingSA.run\u001b[39m\u001b[34m(self, X_for_test, y_for_test, monitor_fun)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m T > \u001b[32m1e-10\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m iteration <= \u001b[38;5;28mself\u001b[39m.max_iterations:\n\u001b[32m    141\u001b[39m     new_bags = \u001b[38;5;28mself\u001b[39m.get_neighbors(bags)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     models = \u001b[43mcreate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_bags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     new_fitness = \u001b[38;5;28mself\u001b[39m.calculate_fitness(models)\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m X_for_test \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_for_test \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\src\\Bagging.py:76\u001b[39m, in \u001b[36mcreate_models\u001b[39m\u001b[34m(X, y, bags)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_models\u001b[39m(X, y, bags: List[Bag]) -> List[BaggingModel]:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     models = [\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbag\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m bag \u001b[38;5;129;01min\u001b[39;00m bags]\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\src\\Bagging.py:71\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(X, y, bag)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_model\u001b[39m(X, y, bag: Bag) -> BaggingModel:\n\u001b[32m     70\u001b[39m     X_mapped, y_mapped = bag.get_mapped_data(X, y)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     model = \u001b[43mDecisionTreeClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     model.fit(X_mapped, y_mapped)\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BaggingModel(model, bag)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\TMP\\SimulatedAnnealingBagging\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:960\u001b[39m, in \u001b[36mDecisionTreeClassifier.__init__\u001b[39m\u001b[34m(self, criterion, splitter, max_depth, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_features, random_state, max_leaf_nodes, min_impurity_decrease, class_weight, ccp_alpha, monotonic_cst)\u001b[39m\n\u001b[32m    952\u001b[39m __metadata_request__fit = {\u001b[33m\"\u001b[39m\u001b[33mcheck_input\u001b[39m\u001b[33m\"\u001b[39m: metadata_routing.UNUSED}\n\u001b[32m    954\u001b[39m _parameter_constraints: \u001b[38;5;28mdict\u001b[39m = {\n\u001b[32m    955\u001b[39m     **BaseDecisionTree._parameter_constraints,\n\u001b[32m    956\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcriterion\u001b[39m\u001b[33m\"\u001b[39m: [StrOptions({\u001b[33m\"\u001b[39m\u001b[33mgini\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mentropy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlog_loss\u001b[39m\u001b[33m\"\u001b[39m}), Hidden(Criterion)],\n\u001b[32m    957\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclass_weight\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mlist\u001b[39m, StrOptions({\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m}), \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[32m    958\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    961\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    962\u001b[39m     *,\n\u001b[32m    963\u001b[39m     criterion=\u001b[33m\"\u001b[39m\u001b[33mgini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    964\u001b[39m     splitter=\u001b[33m\"\u001b[39m\u001b[33mbest\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    965\u001b[39m     max_depth=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    966\u001b[39m     min_samples_split=\u001b[32m2\u001b[39m,\n\u001b[32m    967\u001b[39m     min_samples_leaf=\u001b[32m1\u001b[39m,\n\u001b[32m    968\u001b[39m     min_weight_fraction_leaf=\u001b[32m0.0\u001b[39m,\n\u001b[32m    969\u001b[39m     max_features=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    970\u001b[39m     random_state=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    971\u001b[39m     max_leaf_nodes=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    972\u001b[39m     min_impurity_decrease=\u001b[32m0.0\u001b[39m,\n\u001b[32m    973\u001b[39m     class_weight=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    974\u001b[39m     ccp_alpha=\u001b[32m0.0\u001b[39m,\n\u001b[32m    975\u001b[39m     monotonic_cst=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    976\u001b[39m ):\n\u001b[32m    977\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    978\u001b[39m         criterion=criterion,\n\u001b[32m    979\u001b[39m         splitter=splitter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    990\u001b[39m         ccp_alpha=ccp_alpha,\n\u001b[32m    991\u001b[39m     )\n\u001b[32m    993\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, check_input=\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def get_measures(predictions, y_test):\n",
    "    correct_pred_amount = 0\n",
    "    wrong_pred_amount = 0\n",
    "    accuracy = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == y_test[i]:\n",
    "            correct_pred_amount += 1\n",
    "        else:\n",
    "            wrong_pred_amount += 1\n",
    "    accuracy = correct_pred_amount / (correct_pred_amount + wrong_pred_amount)\n",
    "    return accuracy, correct_pred_amount, wrong_pred_amount\n",
    "    \n",
    "\n",
    "def evaluate_bagging(X_train, y_train, X_test, y_test, n_trees: int) -> Tuple[float, int, int]:\n",
    "    bags = create_bags(X_train, bags_amount=n_trees)\n",
    "    models = create_models(X=X_train, y=y_train, bags=bags)\n",
    "    predictions = predict(X=X_test, models=models)\n",
    "    accuracy, correct_pred_amount, wrong_pred_amount = get_measures(predictions, y_test)\n",
    "    return accuracy, correct_pred_amount, wrong_pred_amount\n",
    "    \n",
    "def evaluate_bagging_sa(X_train, y_train, X_test, y_test, n_trees: int) -> Tuple[float, int, int]: \n",
    "    bagging_sa = BaggingSA(X=X_train, y=y_train,\n",
    "                            T0=10, cooling_method='geometric', alpha=0.99, max_iterations=2500, n_trees=n_trees,\n",
    "                            fitness_accuracy_disagreement_ratio=0.8,\n",
    "                            feature_mutation_chance=0.3, test_split_amount=10)\n",
    "    models = bagging_sa.run()\n",
    "    predictions = predict(X=X_test, models=models)\n",
    "    accuracy, correct_pred_amount, wrong_pred_amount = get_measures(predictions, y_test)\n",
    "    return accuracy, correct_pred_amount, wrong_pred_amount\n",
    "    \n",
    "def evaluate_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy, correct_pred_amount, wrong_pred_amount = get_measures(y_pred, y_test)\n",
    "    return accuracy, correct_pred_amount, wrong_pred_amount\n",
    "\n",
    "\n",
    "result = []\n",
    "print(f\"Start at {pd.Timestamp.now()}\")\n",
    "for dataset in datasets:\n",
    "    X, y = get_dataset(dataset)       \n",
    "    sub_groups_X = np.array_split(np.array(X), k_cross)\n",
    "    sub_groups_y = np.array_split(np.array(y), k_cross) \n",
    "         \n",
    "    for n_tree in n_trees:\n",
    "        for k in range(k_cross):\n",
    "            X_train = np.concatenate(sub_groups_X[:k] + sub_groups_X[k+1:])\n",
    "            y_train = np.concatenate(sub_groups_y[:k] + sub_groups_y[k+1:])\n",
    "            X_test = sub_groups_X[k]\n",
    "            y_test = sub_groups_y[k]\n",
    "            \n",
    "            dt_acc, dt_correct, dt_wrong = evaluate_decision_tree(X_train, y_train, X_test, y_test)\n",
    "            bagging_acc, bagging_correct, bagging_wrong = evaluate_bagging(X_train, y_train, X_test, y_test, n_trees=n_tree)\n",
    "            bagging_sa_acc, bagging_sa_correct, bagging_sa_wrong = evaluate_bagging_sa(X_train, y_train, X_test, y_test, n_trees=n_tree)\n",
    "            \n",
    "            print(f\"Dataset: {dataset}, n_trees: {n_tree}, k: {k}/{k_cross} >> DT: {dt_acc:.4f}, Bagging: {bagging_acc:.4f}, BaggingSA: {bagging_sa_acc:.4f}\")\n",
    "            \n",
    "            result.append([\n",
    "                dataset, n_tree, k, dt_acc, bagging_acc, bagging_sa_acc,\n",
    "                dt_correct, bagging_correct, bagging_sa_correct,\n",
    "                dt_wrong, bagging_wrong, bagging_sa_wrong\n",
    "            ])\n",
    "            \n",
    "            df = pd.DataFrame(result, columns=[\n",
    "                'dataset', 'nTrees', 'kCrossIndex', 'dtAccuracy', 'baggingAccuracy', 'baggingSAAccuracy',\n",
    "                'dtCorrectPred', 'baggingCorrectPred', 'baggingSACorrectPred',\n",
    "                'dtWrongPred', 'baggingWrongPred', 'baggingSAWrongPred'\n",
    "            ])\n",
    "            \n",
    "            df.to_csv(f'./../res_article/accuracy_comparison_{dataset}.csv', index=False)                   \n",
    "                \n",
    "            \n",
    "df_aggregated = df.groupby(['dataset', 'nTrees']).agg(\n",
    "    dataset=('dataset', 'first'),\n",
    "    nTrees=('nTrees', 'first'),\n",
    "    \n",
    "    dtAccuracy=('dtAccuracy', 'mean'),\n",
    "    dtAccuracyStd=('dtAccuracy', 'std'),\n",
    "    baggingAccuracy=('baggingAccuracy', 'mean'),\n",
    "    baggingAccuracyStd=('baggingAccuracy', 'std'),\n",
    "    baggingSAAccuracy=('baggingSAAccuracy', 'mean'),\n",
    "    baggingSAAccuracyStd=('baggingSAAccuracy', 'std'),\n",
    "    \n",
    "    dtCorrectPred=('dtCorrectPred', 'mean'),\n",
    "    dtCorrectPredStd=('dtCorrectPred', 'std'),\n",
    "    baggingCorrectPred=('baggingCorrectPred', 'mean'),\n",
    "    baggingCorrectPredStd=('baggingCorrectPred', 'std'),\n",
    "    baggingSACorrectPred=('baggingSACorrectPred', 'mean'),\n",
    "    baggingSACorrectPredStd=('baggingSACorrectPred', 'std'),\n",
    "    \n",
    "    dtWrongPred=('dtWrongPred', 'mean'),\n",
    "    dtWrongPredStd=('dtWrongPred', 'std'),\n",
    "    baggingWrongPred=('baggingWrongPred', 'mean'),\n",
    "    baggingWrongPredStd=('baggingWrongPred', 'std'),\n",
    "    baggingSAWrongPred=('baggingSAWrongPred', 'mean'),\n",
    "    baggingSAWrongPredStd=('baggingSAWrongPred', 'std')\n",
    ").reset_index(drop=True)\n",
    "df_aggregated.to_csv('./../res_article/results_comparison_aggregated.csv', index=False)\n",
    "print(df_aggregated)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
